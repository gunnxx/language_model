{
	"embedding_dim": 20,
	"lstm_hidden_dim": 30,
	"fc_hidden_dim": 256,
	"vocab_size": 20000,
	"num_layers": 2,
	"bidirectional": false,

	"learning_rate": 1e-3,
	"batch_size": 32,
	"num_epochs": 200
}